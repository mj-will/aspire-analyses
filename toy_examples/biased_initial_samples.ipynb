{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12aa67e6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Biased initial samples\n",
    "\n",
    "This example walks through correcting a biased set of initial samples\n",
    "to recover the true posterior using Aspire's flow-based samplers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d288f73",
   "metadata": {},
   "source": [
    "## Set up the environment\n",
    "Import the core scientific stack along with Aspire utilities for logging,\n",
    "plotting, and handling sample collections.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d3492e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from scipy.stats import norm, uniform, expon\n",
    "\n",
    "from aspire import Aspire\n",
    "from aspire.samples import Samples\n",
    "from aspire.utils import configure_logger, AspireFile\n",
    "from aspire.plot import plot_comparison\n",
    "\n",
    "# Configure the logger\n",
    "configure_logger(\"INFO\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a2ccf06",
   "metadata": {},
   "source": [
    "## Configure output paths\n",
    "Create a reproducible random number generator and ensure the directory used to\n",
    "store figures and results exists.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c0fef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "outdir = Path(\"outdir\") / \"biased_example\"\n",
    "outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "rng = np.random.default_rng(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f3fd7a",
   "metadata": {},
   "source": [
    "## Describe the target distribution\n",
    "Specify the one-dimensional marginals that define our four-dimensional target\n",
    "and wrap them in likelihood and prior helper functions consumed by Aspire.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5102c261",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dists = [\n",
    "    norm(loc=6, scale=0.2),\n",
    "    expon(scale=1),\n",
    "    norm(loc=5, scale=1),\n",
    "    uniform(loc=-10, scale=20),\n",
    "]\n",
    "\n",
    "prior_bounds = [\n",
    "    (-10, 10),\n",
    "    (0, 10),\n",
    "    (-10, 10),\n",
    "    (-10, 10),\n",
    "]\n",
    "dims = len(dists)\n",
    "parameters = [f\"x_{i}\" for i in range(dims)]\n",
    "\n",
    "\n",
    "def log_likelihood(samples: Samples):\n",
    "    x = samples.x\n",
    "    log_prob = np.zeros(x.shape[0])\n",
    "    for i, dist in enumerate(dists):\n",
    "        log_prob += dist.logpdf(x[:, i])\n",
    "    return log_prob\n",
    "\n",
    "\n",
    "def log_prior(samples: Samples):\n",
    "    log_prob = np.zeros(samples.x.shape[0])\n",
    "    for i, bounds in enumerate(prior_bounds):\n",
    "        log_prob += uniform(bounds[0], bounds[1] - bounds[0]).logpdf(samples.x[:, i])\n",
    "    return log_prob\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf1e4c6",
   "metadata": {},
   "source": [
    "## Draw biased initial samples\n",
    "Generate intentionally biased proposal samples alongside reference draws from\n",
    "the true distribution, then instantiate the `Aspire` object that will learn a\n",
    "correcting flow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91685b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "n_init = 1_000\n",
    "\n",
    "x_initial = np.concatenate([\n",
    "    rng.normal(loc=2, scale=1, size=(n_init, 1)),\n",
    "    rng.exponential(scale=1, size=(n_init, 1)),\n",
    "    rng.normal(loc=0, scale=1, size=(n_init, 1)),\n",
    "    # rng.uniform(low=-10, high=10, size=(n_init, 1)),\n",
    "    rng.uniform(low=-10, high=10, size=(n_init, 1)),\n",
    "], axis=1)\n",
    "\n",
    "x_true = np.concatenate([\n",
    "    dist.rvs(size=(n_init, 1), random_state=rng) for dist in dists\n",
    "], axis=1)\n",
    "\n",
    "dims = x_initial.shape[1]\n",
    "parameters = [f\"x_{i}\" for i in range(dims)]\n",
    "initial_samples = Samples(\n",
    "    x=x_initial,\n",
    "    parameters=parameters,\n",
    ")\n",
    "true_samples = Samples(\n",
    "    x=x_true,\n",
    "    parameters=parameters,\n",
    ")\n",
    "# Define the parameters and prior bounds\n",
    "prior_bounds_dict = {p: b for p, b in zip(parameters, prior_bounds)}\n",
    "\n",
    "# Define the aspire object\n",
    "poppy = Aspire(\n",
    "    log_likelihood=log_likelihood,\n",
    "    log_prior=log_prior,\n",
    "    dims=dims,\n",
    "    parameters=parameters,\n",
    "    prior_bounds=prior_bounds_dict,\n",
    "    flow_matching=False,\n",
    "    flow_backend=\"zuko\",\n",
    "    bounded_to_unbounded=True,\n",
    "    hidden_features=[32, 32],\n",
    "    device=\"cpu\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099676c9",
   "metadata": {},
   "source": [
    "## Train the flow model\n",
    "Fit the normalizing flow to the initial samples and monitor optimisation via\n",
    "the loss curve.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d61dfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Fit the flow to the initial samples\n",
    "history = poppy.fit(\n",
    "    initial_samples,\n",
    "    n_epochs=100,\n",
    "    lr_annealing=True,\n",
    "    batch_size=256,\n",
    ")\n",
    "# Plot the loss\n",
    "fig = history.plot_loss()\n",
    "fig.savefig(outdir / \"loss.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202423c3",
   "metadata": {},
   "source": [
    "## Compare flow-based importance samples\n",
    "Use the trained flow to generate new samples, and visualise how they compare to\n",
    "the original biased set and the ground truth.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15feca42",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "is_samples = poppy.sample_posterior(10_000)\n",
    "\n",
    "\n",
    "fig = plot_comparison(\n",
    "    initial_samples,\n",
    "    true_samples,\n",
    "    is_samples,\n",
    "    is_samples,\n",
    "    per_samples_kwargs=[\n",
    "        dict(include_weights=True, color=\"C0\"),\n",
    "        dict(include_weights=False, color=\"k\"),\n",
    "        dict(include_weights=False, color=\"lightgrey\"),\n",
    "        dict(include_weights=True, color=\"C1\"),\n",
    "    ],\n",
    "    labels=[\"Initial samples\", \"True samples\", \"Flow samples\", \"IS samples\"],\n",
    ")\n",
    "fig.savefig(outdir / \"initial_samples.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6645cdce",
   "metadata": {},
   "source": [
    "## Refine with sequential Monte Carlo\n",
    "Run Aspire's SMC sampler to further correct the proposal and inspect the\n",
    "particle evolution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5f22bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Produce samples from the posterior\n",
    "samples, smc_history = poppy.sample_posterior(\n",
    "    1000,\n",
    "    sampler=\"smc\",\n",
    "    return_history=True,\n",
    "    n_final_samples=5000,\n",
    "    sampler_kwargs=dict(\n",
    "        n_steps=32,\n",
    "    ),\n",
    ")\n",
    "\n",
    "fig = smc_history.plot()\n",
    "fig.savefig(outdir / \"history.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dea1aa",
   "metadata": {},
   "source": [
    "## Persist results\n",
    "Write the flow history, SMC diagnostics, and posterior samples to disk so the\n",
    "analysis can be reproduced or extended.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2402f48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the the results to a file\n",
    "# The AspireFile is a small wrapper around h5py.File that automatically\n",
    "# includes additional metadata\n",
    "with AspireFile(outdir / \"poppy_result.h5\", \"w\") as f:\n",
    "    # poppy.save_config(f, \"poppy_config\")\n",
    "    samples.save(f, \"smc/posterior_samples\")\n",
    "    history.save(f, \"flow/history\")\n",
    "    smc_history.save(f, \"smc/history\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e209cc1",
   "metadata": {},
   "source": [
    "## Final posterior comparison\n",
    "Contrast the SMC posterior samples against the earlier flow draws to check that\n",
    "corrections removed the bias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "884683d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig = plot_comparison(\n",
    "    initial_samples,\n",
    "    true_samples,\n",
    "    is_samples,\n",
    "    samples,\n",
    "    per_samples_kwargs=[\n",
    "        dict(include_weights=True, color=\"C0\"),\n",
    "        dict(include_weights=False, color=\"k\"),\n",
    "        dict(include_weights=False, color=\"lightgrey\"),\n",
    "        dict(include_weights=False, color=\"C1\"),\n",
    "    ],\n",
    "    labels=[\"Initial samples\", \"True samples\", \"Flow samples\", \"SMC samples\"],\n",
    ")\n",
    "fig.savefig(outdir / \"posterior_samples.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aspire",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
